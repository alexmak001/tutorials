{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USPS Data Prediction Using Daimensions\n",
    "\n",
    "This dataset is from OpenML who describes the data as, \"Normalized handwritten digits, automatically scanned from envelopes by the U.S. Postal Service.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup\n",
    "\n",
    "We'll get the csv from the OpenML link and use a pandas dataframe to split it into training and validation data in csv's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>int0</th>\n      <th>double1</th>\n      <th>double2</th>\n      <th>double3</th>\n      <th>double4</th>\n      <th>double5</th>\n      <th>double6</th>\n      <th>double7</th>\n      <th>double8</th>\n      <th>double9</th>\n      <th>...</th>\n      <th>double247</th>\n      <th>double248</th>\n      <th>double249</th>\n      <th>double250</th>\n      <th>double251</th>\n      <th>double252</th>\n      <th>double253</th>\n      <th>double254</th>\n      <th>double255</th>\n      <th>double256</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>9298.000000</td>\n      <td>9298.000000</td>\n      <td>9298.000000</td>\n      <td>9298.000000</td>\n      <td>9298.000000</td>\n      <td>9298.000000</td>\n      <td>9298.000000</td>\n      <td>9298.000000</td>\n      <td>9298.000000</td>\n      <td>9298.000000</td>\n      <td>...</td>\n      <td>9298.000000</td>\n      <td>9298.000000</td>\n      <td>9298.000000</td>\n      <td>9298.000000</td>\n      <td>9298.000000</td>\n      <td>9298.000000</td>\n      <td>9298.000000</td>\n      <td>9298.000000</td>\n      <td>9298.000000</td>\n      <td>9298.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4.892020</td>\n      <td>-0.991800</td>\n      <td>-0.972226</td>\n      <td>-0.930421</td>\n      <td>-0.852805</td>\n      <td>-0.733673</td>\n      <td>-0.578239</td>\n      <td>-0.391187</td>\n      <td>-0.228260</td>\n      <td>-0.220399</td>\n      <td>...</td>\n      <td>-0.292865</td>\n      <td>-0.118513</td>\n      <td>-0.138364</td>\n      <td>-0.357547</td>\n      <td>-0.595574</td>\n      <td>-0.766226</td>\n      <td>-0.874332</td>\n      <td>-0.936784</td>\n      <td>-0.970873</td>\n      <td>-0.989597</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.001086</td>\n      <td>0.050814</td>\n      <td>0.118296</td>\n      <td>0.195285</td>\n      <td>0.284053</td>\n      <td>0.372653</td>\n      <td>0.435317</td>\n      <td>0.452878</td>\n      <td>0.454537</td>\n      <td>0.446069</td>\n      <td>...</td>\n      <td>0.483898</td>\n      <td>0.453286</td>\n      <td>0.449512</td>\n      <td>0.456625</td>\n      <td>0.422421</td>\n      <td>0.340464</td>\n      <td>0.254392</td>\n      <td>0.183444</td>\n      <td>0.120247</td>\n      <td>0.058028</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>...</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-0.999914</td>\n      <td>-0.996085</td>\n      <td>-0.963110</td>\n      <td>-0.787003</td>\n      <td>-0.620084</td>\n      <td>-0.571667</td>\n      <td>...</td>\n      <td>-0.742622</td>\n      <td>-0.430494</td>\n      <td>-0.465960</td>\n      <td>-0.770638</td>\n      <td>-0.968697</td>\n      <td>-0.997447</td>\n      <td>-0.999957</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5.000000</td>\n      <td>-1.000000</td>\n      <td>-0.999992</td>\n      <td>-0.999608</td>\n      <td>-0.991661</td>\n      <td>-0.932991</td>\n      <td>-0.747495</td>\n      <td>-0.447743</td>\n      <td>-0.138583</td>\n      <td>-0.147614</td>\n      <td>...</td>\n      <td>-0.283600</td>\n      <td>-0.022176</td>\n      <td>-0.039908</td>\n      <td>-0.392889</td>\n      <td>-0.755935</td>\n      <td>-0.946957</td>\n      <td>-0.993475</td>\n      <td>-0.999771</td>\n      <td>-0.999996</td>\n      <td>-1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7.000000</td>\n      <td>-0.999969</td>\n      <td>-0.998444</td>\n      <td>-0.979572</td>\n      <td>-0.861493</td>\n      <td>-0.589829</td>\n      <td>-0.260331</td>\n      <td>0.000547</td>\n      <td>0.143727</td>\n      <td>0.148815</td>\n      <td>...</td>\n      <td>0.153227</td>\n      <td>0.251788</td>\n      <td>0.220543</td>\n      <td>0.033934</td>\n      <td>-0.306862</td>\n      <td>-0.654382</td>\n      <td>-0.885085</td>\n      <td>-0.979766</td>\n      <td>-0.998040</td>\n      <td>-0.999942</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>10.000000</td>\n      <td>0.000308</td>\n      <td>0.332928</td>\n      <td>0.479436</td>\n      <td>0.523534</td>\n      <td>0.527370</td>\n      <td>0.531509</td>\n      <td>0.531319</td>\n      <td>0.531368</td>\n      <td>0.531327</td>\n      <td>...</td>\n      <td>0.531380</td>\n      <td>0.531834</td>\n      <td>0.531857</td>\n      <td>0.531830</td>\n      <td>0.531472</td>\n      <td>0.523678</td>\n      <td>0.524670</td>\n      <td>0.470479</td>\n      <td>0.314115</td>\n      <td>-0.162598</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 257 columns</p>\n</div>",
      "text/plain": "              int0      double1      double2      double3      double4  \\\ncount  9298.000000  9298.000000  9298.000000  9298.000000  9298.000000   \nmean      4.892020    -0.991800    -0.972226    -0.930421    -0.852805   \nstd       3.001086     0.050814     0.118296     0.195285     0.284053   \nmin       1.000000    -1.000000    -1.000000    -1.000000    -1.000000   \n25%       2.000000    -1.000000    -1.000000    -1.000000    -0.999914   \n50%       5.000000    -1.000000    -0.999992    -0.999608    -0.991661   \n75%       7.000000    -0.999969    -0.998444    -0.979572    -0.861493   \nmax      10.000000     0.000308     0.332928     0.479436     0.523534   \n\n           double5      double6      double7      double8      double9  ...  \\\ncount  9298.000000  9298.000000  9298.000000  9298.000000  9298.000000  ...   \nmean     -0.733673    -0.578239    -0.391187    -0.228260    -0.220399  ...   \nstd       0.372653     0.435317     0.452878     0.454537     0.446069  ...   \nmin      -1.000000    -1.000000    -1.000000    -1.000000    -1.000000  ...   \n25%      -0.996085    -0.963110    -0.787003    -0.620084    -0.571667  ...   \n50%      -0.932991    -0.747495    -0.447743    -0.138583    -0.147614  ...   \n75%      -0.589829    -0.260331     0.000547     0.143727     0.148815  ...   \nmax       0.527370     0.531509     0.531319     0.531368     0.531327  ...   \n\n         double247    double248    double249    double250    double251  \\\ncount  9298.000000  9298.000000  9298.000000  9298.000000  9298.000000   \nmean     -0.292865    -0.118513    -0.138364    -0.357547    -0.595574   \nstd       0.483898     0.453286     0.449512     0.456625     0.422421   \nmin      -1.000000    -1.000000    -1.000000    -1.000000    -1.000000   \n25%      -0.742622    -0.430494    -0.465960    -0.770638    -0.968697   \n50%      -0.283600    -0.022176    -0.039908    -0.392889    -0.755935   \n75%       0.153227     0.251788     0.220543     0.033934    -0.306862   \nmax       0.531380     0.531834     0.531857     0.531830     0.531472   \n\n         double252    double253    double254    double255    double256  \ncount  9298.000000  9298.000000  9298.000000  9298.000000  9298.000000  \nmean     -0.766226    -0.874332    -0.936784    -0.970873    -0.989597  \nstd       0.340464     0.254392     0.183444     0.120247     0.058028  \nmin      -1.000000    -1.000000    -1.000000    -1.000000    -1.000000  \n25%      -0.997447    -0.999957    -1.000000    -1.000000    -1.000000  \n50%      -0.946957    -0.993475    -0.999771    -0.999996    -1.000000  \n75%      -0.654382    -0.885085    -0.979766    -0.998040    -0.999942  \nmax       0.523678     0.524670     0.470479     0.314115    -0.162598  \n\n[8 rows x 257 columns]"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using pandas to get csv as a dataframe and see how it looks\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset_url = 'https://www.openml.org/data/get_csv/19329737/usps.csv'\n",
    "data = pd.read_csv(dataset_url)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing csv's, y is for the target column (int0)\n",
    "y = data.int0\n",
    "X = data.drop('int0', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2)\n",
    "pd.concat([X_train, y_train], axis=1).to_csv('usps_train.csv',index=False)\n",
    "pd.concat([X_test, y_test], axis=1).to_csv('usps_valid.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Brainome via Pip\n",
    "Simply run the cell below in order to install Brainome and be able to use it in terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install brainome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get Measurements\n",
    "\n",
    "We always want to measure our data before building our predictor in order to ensure we are building the right model. For more information about how to use Daimensions and why we want to measure our data beforehand, check out the Titanic notebook. Don't forget to use -target int0 because the target column is not on the very right for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Could not detect a GPU. Neural Network generation will be slow.\n",
      "\n",
      "\u001b[01;1mBrainome Table Compiler v1.005-7-prod\u001b[0m\n",
      "Copyright (c) 2019-2021 Brainome, Inc. All Rights Reserved.\n",
      "Licensed to:                 Alexander Makhratchev  (Evaluation)\n",
      "Expiration Date:             2021-08-31   29 days left\n",
      "Maximum File Size:           30 GB\n",
      "Maximum Instances:           unlimited\n",
      "Maximum Attributes:          unlimited\n",
      "Maximum Classes:             unlimited\n",
      "Connected to:                daimensions.brainome.ai  (local execution)\n",
      "\n",
      "\u001b[01;1mCommand:\u001b[0m\n",
      "    btc -measureonly usps_train.csv -target int0\n",
      "\n",
      "Start Time:                 08/02/2021, 13:05 PDT\n",
      "\n",
      "Cleaning...done. \n",
      "Splitting into training and validation...done. \n",
      "Pre-training measurements...done. \n",
      "\n",
      "\n",
      "\u001b[01;1mPre-training Measurements\u001b[0m\n",
      "Data:\n",
      "    Input:                      usps_train.csv\n",
      "    Target Column:              int0\n",
      "    Number of instances:       7438\n",
      "    Number of attributes:       256 out of 256\n",
      "    Number of classes:           10\n",
      "\n",
      "Class Balance:                \n",
      "                               9: 7.64%\n",
      "                               3: 9.94%\n",
      "                               2: 13.50%\n",
      "                              10: 8.85%\n",
      "                               1: 17.03%\n",
      "                               5: 9.48%\n",
      "                               6: 7.49%\n",
      "                               7: 9.09%\n",
      "                               4: 8.73%\n",
      "                               8: 8.27%\n",
      "\n",
      "Learnability:\n",
      "    Best guess accuracy:          17.03%\n",
      "    Data Sufficiency:             Maybe enough data to generalize. [yellow]\n",
      "\n",
      "Capacity Progression:             at [ 5%, 10%, 20%, 40%, 80%, 100% ]\n",
      "    Ideal Machine Learner:             10,  11,  12,  12,  13,  13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Expected Generalization:\n",
      "    Decision Tree:                 4.07 bits/bit\n",
      "    Neural Network:                6.99 bits/bit\n",
      "    Random Forest:                54.69 bits/bit\n",
      "\n",
      "Expected Accuracy:              Training            Validation\n",
      "    Decision Tree:               100.00%                19.74%\n",
      "    Neural Network:                 ----                  ----\n",
      "    Random Forest:               100.00%                96.35%\n",
      "\n",
      "Recommendations:\n",
      "    We recommend using Random Forest -f RF.\n",
      "    If TPR of all classes are important and your data is unbalanced, try using the option -balance to improve all TPRs.\n",
      "    If predictor accuracy is insufficient, try using the effort option -e with a value of 5 or more to increase training time. \n",
      "\n",
      "Time to Build Estimates:\n",
      "    Decision Tree:                a few seconds\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "End Time:           08/02/2021, 13:06 PDT\n",
      "Runtime Duration:   1m 11s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! brainome -measureonly usps_train.csv -target int0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the Predictor\n",
    "\n",
    "Based on our measurements, Daimensions recommends we use a neural network (higher expected generalization) and more effort for this dataset. Don't forget to use -target because the target column isn't on the very right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Could not detect a GPU. Neural Network generation will be slow.\n",
      "\n",
      "\u001b[01;1mBrainome Table Compiler v1.005-7-prod\u001b[0m\n",
      "Copyright (c) 2019-2021 Brainome, Inc. All Rights Reserved.\n",
      "Licensed to:                 Alexander Makhratchev  (Evaluation)\n",
      "Expiration Date:             2021-08-31   29 days left\n",
      "Maximum File Size:           30 GB\n",
      "Maximum Instances:           unlimited\n",
      "Maximum Attributes:          unlimited\n",
      "Maximum Classes:             unlimited\n",
      "Connected to:                daimensions.brainome.ai  (local execution)\n",
      "\n",
      "\u001b[01;1mCommand:\u001b[0m\n",
      "    btc -f NN usps_train.csv -o usps_predict.py -target int0 -e 5 --yes\n",
      "\n",
      "Start Time:                 08/02/2021, 13:06 PDT\n",
      "\n",
      "Cleaning...done. \n",
      "Splitting into training and validation...done. \n",
      "Pre-training measurements...done. \n",
      "\n",
      "\n",
      "\u001b[01;1mPre-training Measurements\u001b[0m\n",
      "Data:\n",
      "    Input:                      usps_train.csv\n",
      "    Target Column:              int0\n",
      "    Number of instances:       7438\n",
      "    Number of attributes:       256 out of 256\n",
      "    Number of classes:           10\n",
      "\n",
      "Class Balance:                \n",
      "                               9: 7.64%\n",
      "                               3: 9.94%\n",
      "                               2: 13.50%\n",
      "                              10: 8.85%\n",
      "                               1: 17.03%\n",
      "                               5: 9.48%\n",
      "                               6: 7.49%\n",
      "                               7: 9.09%\n",
      "                               4: 8.73%\n",
      "                               8: 8.27%\n",
      "\n",
      "Learnability:\n",
      "    Best guess accuracy:          17.03%\n",
      "    Data Sufficiency:             Maybe enough data to generalize. [yellow]\n",
      "\n",
      "Capacity Progression:             at [ 5%, 10%, 20%, 40%, 80%, 100% ]\n",
      "    Ideal Machine Learner:             10,  11,  12,  12,  13,  13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Expected Generalization:\n",
      "    Decision Tree:                 4.07 bits/bit\n",
      "    Neural Network:                6.99 bits/bit\n",
      "    Random Forest:                54.69 bits/bit\n",
      "\n",
      "Expected Accuracy:              Training            Validation\n",
      "    Decision Tree:               100.00%                19.74%\n",
      "    Neural Network:                 ----                  ----\n",
      "    Random Forest:               100.00%                96.35%\n",
      "\n",
      "Recommendations:\n",
      "    We recommend using Random Forest -f RF.\n",
      "    If TPR of all classes are important and your data is unbalanced, try using the option -balance to improve all TPRs.\n",
      "    Model type NN given by user. \n",
      "\n",
      "\n",
      "Architecting model...done. \n",
      "Priming model...done. \n",
      "Training...done. \n",
      "Compiling predictor...done. \n",
      "Validating predictor...done. \n",
      "\n",
      "\u001b[01;1mPredictor:\u001b[0m                        usps_predict.py\n",
      "    Classifier Type:              Neural Network\n",
      "    System Type:                  10-way classifier\n",
      "    Training / Validation Split:  60% : 40%\n",
      "    Accuracy:\n",
      "      Best-guess accuracy:        17.03%\n",
      "      Training accuracy:          96.43% (4300/4459 correct)\n",
      "      Validation Accuracy:        94.36% (2811/2979 correct)\n",
      "      Combined Model Accuracy:    95.60% (7111/7438 correct)\n",
      "\n",
      "    Model Capacity (MEC):        322    bits\n",
      "\n",
      "    Generalization Ratio:         43.65 bits/bit\n",
      "    Percent of Data Memorized:     8.40%\n",
      "    Resilience to Noise:          -1.13 dB\n",
      "\n",
      "\n",
      "    Training Confusion Matrix:\n",
      "              Actual | Predicted\n",
      "              ------ | ---------\n",
      "                   9 |   324     1     1     2     2     1     3     0     5     1 \n",
      "                   3 |     1   422     2     0     2     8     1     3     2     2 \n",
      "                   2 |     1     0   598     0     0     1     0     1     1     0 \n",
      "                  10 |     0     1     0   380     0     8     0     0     1     4 \n",
      "                   1 |     3     4     0     0   746     1     2     3     1     0 \n",
      "                   5 |     1     3     2    11     0   401     0     5     0     0 \n",
      "                   6 |     3     1     0     1     5     2   310     4     7     1 \n",
      "                   7 |     1     2     0     0     1     4     0   397     0     0 \n",
      "                   4 |     3     2     0     0     2     1    10     0   369     2 \n",
      "                   8 |     2     2     0    11     0     1     0     0     0   353 \n",
      "\n",
      "    Validation Confusion Matrix:\n",
      "              Actual | Predicted\n",
      "              ------ | ---------\n",
      "                   9 |   204     1     9     3     2     2     2     1     2     2 \n",
      "                   3 |     2   279     0     1     6     2     3     0     2     1 \n",
      "                   2 |     0     0   399     0     0     0     0     2     1     0 \n",
      "                  10 |     2     0     3   240     0     7     1     0     2     9 \n",
      "                   1 |     2     2     0     1   490     2     6     4     0     0 \n",
      "                   5 |     0     5     1    12     0   257     1     6     0     0 \n",
      "                   6 |     2     0     0     1     6     1   205     2     6     0 \n",
      "                   7 |     0     2     1     0     1     2     0   265     0     0 \n",
      "                   4 |     5     3     0     0     1     0    11     0   237     3 \n",
      "                   8 |     0     3     0     6     0     1     1     0     0   235 \n",
      "\n",
      "    Training Accuracy by Class:\n",
      "                int0 |    TP    FP    TN    FN     TPR      TNR      PPV      NPV       F1       TS \n",
      "                ---- | ----- ----- ----- ----- -------- -------- -------- -------- -------- --------\n",
      "                   9 |   324    15  4104    16   95.29%   99.64%   95.58%   99.61%   95.43%   91.27%\n",
      "                   3 |   422    16  4000    21   95.26%   99.60%   96.35%   99.48%   95.80%   91.94%\n",
      "                   2 |   598     5  3852     4   99.34%   99.87%   99.17%   99.90%   99.25%   98.52%\n",
      "                  10 |   380    25  4040    14   96.45%   99.38%   93.83%   99.65%   95.12%   90.69%\n",
      "                   1 |   746    12  3687    14   98.16%   99.68%   98.42%   99.62%   98.29%   96.63%\n",
      "                   5 |   401    27  4009    22   94.80%   99.33%   93.69%   99.45%   94.24%   89.11%\n",
      "                   6 |   310    16  4109    24   92.81%   99.61%   95.09%   99.42%   93.94%   88.57%\n",
      "                   7 |   397    16  4038     8   98.02%   99.61%   96.13%   99.80%   97.07%   94.30%\n",
      "                   4 |   369    17  4053    20   94.86%   99.58%   95.60%   99.51%   95.23%   90.89%\n",
      "                   8 |   353    10  4080    16   95.66%   99.76%   97.25%   99.61%   96.45%   93.14%\n",
      "\n",
      "    Validation Accuracy by Class:\n",
      "                int0 |    TP    FP    TN    FN     TPR      TNR      PPV      NPV       F1       TS \n",
      "\n",
      "                   9 |   204    13  2738    24   89.47%   99.53%   94.01%   99.13%   91.69%   84.65%\n",
      "                   3 |   279    16  2667    17   94.26%   99.40%   94.58%   99.37%   94.42%   89.42%\n",
      "                   2 |   399    14  2563     3   99.25%   99.46%   96.61%   99.88%   97.91%   95.91%\n",
      "                  10 |   240    24  2691    24   90.91%   99.12%   90.91%   99.12%   90.91%   83.33%\n",
      "                   1 |   490    16  2456    17   96.65%   99.35%   96.84%   99.31%   96.74%   93.69%\n",
      "                   5 |   257    17  2680    25   91.13%   99.37%   93.80%   99.08%   92.45%   85.95%\n",
      "                   6 |   205    25  2731    18   91.93%   99.09%   89.13%   99.35%   90.51%   82.66%\n",
      "                   7 |   265    15  2693     6   97.79%   99.45%   94.64%   99.78%   96.19%   92.66%\n",
      "                   4 |   237    13  2706    23   91.15%   99.52%   94.80%   99.16%   92.94%   86.81%\n",
      "                   8 |   235    15  2718    11   95.53%   99.45%   94.00%   99.60%   94.76%   90.04%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "End Time:           08/02/2021, 13:20 PDT\n",
      "Runtime Duration:   13m 29s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! brainome -f NN usps_train.csv -o usps_predict.py -target int0 -e 5 --yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Validate the Model\n",
    "\n",
    "Now we can validate our model on our test data, a separate set of data that wasn't used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Type:                    Neural Network\n",
      "System Type:                        10-way classifier\n",
      "\n",
      "Accuracy:\n",
      "    Best-guess accuracy:            15.38%\n",
      "    Model accuracy:                 93.54% (1740/1860 correct)\n",
      "    Improvement over best guess:    78.16% (of possible 84.62%)\n",
      "\n",
      "Model capacity (MEC):               322 bits\n",
      "Generalization ratio:               17.71 bits/bit\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "      Actual |          Predicted           \n",
      "    --------------------------------------------------\n",
      "           9 |128   0   3   1   0   0   2   0   6   0\n",
      "           3 |  1 178   0   0   2   3   1   0   3   2\n",
      "           2 |  0   0 264   0   0   0   0   1   0   0\n",
      "          10 |  1   1   0 146   1   4   2   0   1   7\n",
      "           1 |  0   2   0   1 275   2   3   2   1   0\n",
      "           5 |  0   5   1   4   2 131   0   3   1   0\n",
      "           6 |  1   0   0   0   2   1 149   0   5   1\n",
      "           7 |  1   3   1   0   0   1   1 151   0   0\n",
      "           4 |  5   5   0   0   0   0   8   0 157   0\n",
      "           8 |  3   2   1   5   0   2   3   0   0 161\n",
      "\n",
      "Accuracy by Class:\n",
      "\n",
      "      target |  TP FP   TN FN     TPR     TNR     PPV     NPV      F1      TS\n",
      "    -------- | --- -- ---- -- ------- ------- ------- ------- ------- -------\n",
      "           9 | 128 12 1708 12  91.43%  99.30%  91.43%  99.30%  91.43%  84.21%\n",
      "           3 | 178 18 1652 12  93.68%  98.92%  90.82%  99.28%  92.23%  85.58%\n",
      "           2 | 264  6 1589  1  99.62%  99.62%  97.78%  99.94%  98.69%  97.42%\n",
      "          10 | 146 11 1686 17  89.57%  99.35%  92.99%  99.00%  91.25%  83.91%\n",
      "           1 | 275  7 1567 11  96.15%  99.56%  97.52%  99.30%  96.83%  93.86%\n",
      "           5 | 131 13 1700 16  89.12%  99.24%  90.97%  99.07%  90.03%  81.88%\n",
      "           6 | 149 20 1681 10  93.71%  98.82%  88.17%  99.41%  90.85%  83.24%\n",
      "           7 | 151  6 1696  7  95.57%  99.65%  96.18%  99.59%  95.87%  92.07%\n",
      "           4 | 157 17 1668 18  89.71%  98.99%  90.23%  98.93%  89.97%  81.77%\n",
      "           8 | 161 10 1673 16  90.96%  99.41%  94.15%  99.05%  92.53%  86.10%\n"
     ]
    }
   ],
   "source": [
    "! python3 usps_predict.py -validate usps_valid.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray! We have validated the accuracy of our model and found that it has a 93.54% accuracy for the test data. We can also see the confusion matrix, which tells us the percentage of data points from each class (columns) that were predicted to be in a certain class (rows). The diagonals are correctly predicted data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "name": "python376jvsc74a57bd0a876d5d129613f84737ac732b9dceeab4d5b6e46c5cd6a0b580a7fe744c52632"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}