{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Using Daimensions\n",
    "\n",
    "This notebook uses data from the Titanic competition on Kaggle (https://www.kaggle.com/c/titanic/overview).\n",
    "\n",
    "Kaggle's description of the competition:\n",
    "\"The sinking of the Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the widely considered 'unsinkable' RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n",
    "While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others. In this challenge, we ask you to build a predictive model that answers the question: 'what sorts of people were more likely to survive?' using passenger data (ie name, age, gender, socio-economic class, etc).\"\n",
    "\n",
    "Goal: Make a predictor of survival from Titanic training data. We'll do this by using Daimensions to measure, build, and validate a predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Getting Started\n",
    "\n",
    "Because this is the very first tutorial, we'll go over how to install btc and get started. You can also see how to setup btc in the Daimensions Quickstart guide.\n",
    "\n",
    "First, use the following link to download the installation script: https://download.brainome.net/btc-cli/btc-setup.sh. From the download directory, run the following bash command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sh: btc-setup.sh: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! sh btc-setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script will check that your operating system is supported, download the latest btc client to your machine and install it in /usr/local/bin. You will be prompted to enter the administrator password to install the software. \n",
    "*NOTE: After installation, make sure that “/usr/local/bin” is in your search path. *\n",
    "\n",
    "Next, run the following command to wipe all cloud files. You will need your user credentials to login to DaimensionsTM. The first time you login, your license key will be downloaded automatically. Please use the default password that was provided to you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! btc WIPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To change your password, use the following bash command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! btc CHPASSWD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get Measurements\n",
    "\n",
    "Measuring our data before building a predictor is important in order to avoid mistakes and optimize our model. If we don't measure our data, we have no way of knowing whether the predictor we build will actually do what we want it to do when it sees new data that it wasn’t trained on. We'll probably build a model that is much larger than it needs to be, meaning our training and run times will probably be much longer than they need to be. We could end up in a situation where we just don’t know whether we have the right amount or right type of training data, even after extensive training and testing. Because of these reasons, it's best to measure our data beforehand. Not to mention, Daimensions will tell us about learnability, the generalization ratio, noise resilience, and all the standard accuracy and confusion figures. \n",
    "For more information, you can read the Daimensions How-to Guide and Glossary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId,Cabin_Class,Name,Sex,Age,Sibling_Spouse,Parent_Children,Ticket_Number,Fare,Cabin_Number,Port_of_Embarkation,Survived\n",
      "1,3,\"Braund, Mr. Owen Harris\",male,22,1,0,A/5 21171,7.25,,S,died\n",
      "2,1,\"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\",female,38,1,0,PC 17599,71.2833,C85,C,survived\n",
      "3,3,\"Heikkinen, Miss. Laina\",female,26,0,0,STON/O2. 3101282,7.925,,S,survived\n",
      "4,1,\"Futrelle, Mrs. Jacques Heath (Lily May Peel)\",female,35,1,0,113803,53.1,C123,S,survived\n",
      "5,3,\"Allen, Mr. William Henry\",male,35,0,0,373450,8.05,,S,died\n",
      "6,3,\"Moran, Mr. James\",male,,0,0,330877,8.4583,,Q,died\n",
      "7,1,\"McCarthy, Mr. Timothy J\",male,54,0,0,17463,51.8625,E46,S,died\n",
      "8,3,\"Palsson, Master. Gosta Leonard\",male,2,3,1,349909,21.075,,S,died\n",
      "9,3,\"Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)\",female,27,0,2,347742,11.1333,,S,survived\n"
     ]
    }
   ],
   "source": [
    "# Below is a clip of the training data:\n",
    "! head data/titanic_train.csv\n",
    "# For Windows command prompt:\n",
    "# type titanic_train.csv | more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from above, the target column (Survived) isn't the last column on the right. Because of this, we need to use '-target' so that Daimensions is looking at the correct target column for measuring and building a predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Could not detect a GPU. Neural Network generation will be slow.\n",
      "\n",
      "\u001b[01;1mBrainome Table Compiler v1.005-7-prod\u001b[0m\n",
      "Copyright (c) 2019-2021 Brainome, Inc. All Rights Reserved.\n",
      "Licensed to:                 Alexander Makhratchev  (Evaluation)\n",
      "Expiration Date:             2021-08-31   26 days left\n",
      "Maximum File Size:           30 GB\n",
      "Maximum Instances:           unlimited\n",
      "Maximum Attributes:          unlimited\n",
      "Maximum Classes:             unlimited\n",
      "Connected to:                daimensions.brainome.ai  (local execution)\n",
      "\n",
      "\u001b[01;1mCommand:\u001b[0m\n",
      "    btc -measureonly data/titanic_train.csv -target Survived\n",
      "\n",
      "Start Time:                 08/05/2021, 17:11 PDT\n",
      "\n",
      "Cleaning...done. \n",
      "Splitting into training and validation...done. \n",
      "Pre-training measurements...done. \n",
      "\n",
      "\n",
      "\u001b[01;1mPre-training Measurements\u001b[0m\n",
      "Data:\n",
      "    Input:                      data/titanic_train.csv\n",
      "    Target Column:              Survived\n",
      "    Number of instances:        800\n",
      "    Number of attributes:        11 out of 11\n",
      "    Number of classes:            2\n",
      "\n",
      "Class Balance:                \n",
      "                            died: 61.50%\n",
      "                        survived: 38.50%\n",
      "\n",
      "Learnability:\n",
      "    Best guess accuracy:          61.50%\n",
      "    Data Sufficiency:             Maybe enough data to generalize. [yellow]\n",
      "\n",
      "Capacity Progression:             at [ 5%, 10%, 20%, 40%, 80%, 100% ]\n",
      "    Ideal Machine Learner:              6,   7,   8,   8,   9,   9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Expected Generalization:\n",
      "    Decision Tree:                 2.02 bits/bit\n",
      "    Neural Network:                6.52 bits/bit\n",
      "    Random Forest:                10.13 bits/bit\n",
      "\n",
      "Expected Accuracy:              Training            Validation\n",
      "    Decision Tree:               100.00%                52.50%\n",
      "    Neural Network:                 ----                  ----\n",
      "    Random Forest:               100.00%                80.25%\n",
      "\n",
      "Recommendations:\n",
      "    Warning: Data has high information density. Using effort 5 and larger ( -e 5 ) can improve results.\n",
      "    We recommend using Random Forest -f RF.\n",
      "    If predictor accuracy is insufficient, try using the option -rank to automatically select the important attributes.\n",
      "    If predictor accuracy is insufficient, try using the effort option -e with a value of 5 or more to increase training time. \n",
      "\n",
      "Time to Build Estimates:\n",
      "    Decision Tree:                a few seconds\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "End Time:           08/05/2021, 17:11 PDT\n",
      "Runtime Duration:   5s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Measuring the training data:\n",
    "! brainome -measureonly data/titanic_train.csv -target Survived "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the Predictor\n",
    "\n",
    "Because the learnability of the data (based on capacity progression and risk) is yellow, the how-to guide recommends to choose predictor with higher generalization and increase effort for best results. This means using a neural network with effort should work best. Here, I'm using '-f NN' to make the predictor a neural network. I'm also using '-o predict.py' to output the predictor as a python file. To increase the effort, I'm using '-e 10' for 10 times the effort. Again, we have to use '-target Survived' because the target column isn't the last one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Could not detect a GPU. Neural Network generation will be slow.\n",
      "\n",
      "\u001b[01;1mBrainome Table Compiler v1.005-7-prod\u001b[0m\n",
      "Copyright (c) 2019-2021 Brainome, Inc. All Rights Reserved.\n",
      "Licensed to:                 Alexander Makhratchev  (Evaluation)\n",
      "Expiration Date:             2021-08-31   26 days left\n",
      "Maximum File Size:           30 GB\n",
      "Maximum Instances:           unlimited\n",
      "Maximum Attributes:          unlimited\n",
      "Maximum Classes:             unlimited\n",
      "Connected to:                daimensions.brainome.ai  (local execution)\n",
      "\n",
      "\u001b[01;1mCommand:\u001b[0m\n",
      "    btc -v -v -f NN data/titanic_train.csv -o titanic_predict.py -target Survived --yes\n",
      "\n",
      "Start Time:                 08/05/2021, 17:54 PDT\n",
      "\n",
      "Cleaning...done. < 1s\n",
      "Splitting into training and validation...done. 1s\n",
      "Pre-training measurements...done. 2s\n",
      "\n",
      "\n",
      "\u001b[01;1mPre-training Measurements\u001b[0m\n",
      "Data:\n",
      "    Input:                      data/titanic_train.csv\n",
      "    Target Column:              Survived\n",
      "    Number of instances:        800\n",
      "    Number of attributes:        11 out of 11\n",
      "    Number of classes:            2\n",
      "\n",
      "Class Balance:                \n",
      "                            died: 61.50%\n",
      "                        survived: 38.50%\n",
      "\n",
      "Learnability:\n",
      "    Best guess accuracy:          61.50%\n",
      "    Data Sufficiency:             Maybe enough data to generalize. [yellow]\n",
      "\n",
      "Capacity Progression:             at [ 5%, 10%, 20%, 40%, 80%, 100% ]\n",
      "    Ideal Machine Learner:              6,   7,   8,   8,   9,   9\n",
      "\n",
      "Estimated Memory Equivalent Capacity:\n",
      "    Decision Tree:               380 bits\n",
      "    Neural Networks:             118 bits\n",
      "    Random Forest:                79 bits\n",
      "\n",
      "\n",
      "Percent of data that would be memorized:\n",
      "    Decision Tree:               100.31%\n",
      "    Neural Networks:             100.00%\n",
      "    Random Forest:                51.30%\n",
      "\n",
      "\n",
      "Expected Generalization:\n",
      "    Decision Tree:                 2.02 bits/bit\n",
      "    Neural Network:                6.52 bits/bit\n",
      "    Random Forest:                10.13 bits/bit\n",
      "\n",
      "Expected Accuracy:              Training            Validation\n",
      "    Decision Tree:               100.00%                52.50%\n",
      "    Neural Network:                 ----                  ----\n",
      "    Random Forest:               100.00%                80.25%\n",
      "\n",
      "Recommendations:\n",
      "    Warning: Data has high information density. Using effort 5 and larger ( -e 5 ) can improve results.\n",
      "    We recommend using Random Forest -f RF.\n",
      "    If predictor accuracy is insufficient, try using the option -rank to automatically select the important attributes.\n",
      "    If predictor accuracy is insufficient, try using the effort option -e with a value of 5 or more to increase training time.\n",
      "    Model type NN given by user. \n",
      "\n",
      "\n",
      "Architecting model...done. 5s\n",
      "Priming model...done. 30s\n",
      "Model created:\n",
      "Sequential(\n",
      "  (0): Linear(in_features=11, out_features=2, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "Compiling predictor...done. < 1s\n",
      "Validating predictor...done. 1s\n",
      "\n",
      "\u001b[01;1mPredictor:\u001b[0m                        titanic_predict.py\n",
      "    Classifier Type:              Neural Network\n",
      "    System Type:                  Binary classifier\n",
      "    Training / Validation Split:  60% : 40%\n",
      "    Accuracy:\n",
      "      Best-guess accuracy:        61.50%\n",
      "      Training accuracy:          62.83% (301/479 correct)\n",
      "      Validation Accuracy:        61.68% (198/321 correct)\n",
      "      Combined Model Accuracy:    62.37% (499/800 correct)\n",
      "\n",
      "    Model Capacity (MEC):         27    bits\n",
      "\n",
      "    Generalization Ratio:         10.70 bits/bit\n",
      "    Percent of Data Memorized:    18.97%\n",
      "    Resilience to Noise:          -1.05 dB\n",
      "    System Meter Runtime Duration:    1s\n",
      "\n",
      "    Training Confusion Matrix:\n",
      "              Actual | Predicted\n",
      "              ------ | ---------\n",
      "                died |  294    1 \n",
      "            survived |  177    7 \n",
      "\n",
      "    Validation Confusion Matrix:\n",
      "              Actual | Predicted\n",
      "              ------ | ---------\n",
      "                died |  195    2 \n",
      "            survived |  121    3 \n",
      "\n",
      "    Combined Confusion Matrix:\n",
      "              Actual | Predicted\n",
      "              ------ | ---------\n",
      "                died |  489    3 \n",
      "            survived |  298   10 \n",
      "\n",
      "    Training Accuracy by Class:\n",
      "            Survived |   TP   FP   TN   FN     TPR      TNR      PPV      NPV       F1       TS \n",
      "            -------- | ---- ---- ---- ---- -------- -------- -------- -------- -------- --------\n",
      "                died |  294  177    7    1   99.66%    3.80%   62.42%   87.50%   76.76%   62.29%\n",
      "            survived |    7    1  294  177    3.80%   99.66%   87.50%   62.42%    7.29%    3.78%\n",
      "\n",
      "    Validation Accuracy by Class:\n",
      "            Survived |   TP   FP   TN   FN     TPR      TNR      PPV      NPV       F1       TS \n",
      "            -------- | ---- ---- ---- ---- -------- -------- -------- -------- -------- --------\n",
      "                died |  195  121    3    2   98.98%    2.42%   61.71%   60.00%   76.02%   61.32%\n",
      "            survived |    3    2  195  121    2.42%   98.98%   60.00%   61.71%    4.65%    2.38%\n",
      "\n",
      "    Combined Accuracy by Class:\n",
      "            Survived |   TP   FP   TN   FN     TPR      TNR      PPV      NPV       F1       TS \n",
      "            -------- | ---- ---- ---- ---- -------- -------- -------- -------- -------- --------\n",
      "                died |  489  298   10    3   99.39%    3.25%   62.13%   76.92%   76.47%   61.90%\n",
      "            survived |   10    3  489  298    3.25%   99.39%   76.92%   62.13%    6.23%    3.22%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "End Time:           08/05/2021, 17:55 PDT\n",
      "Runtime Duration:   41s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Building the predictor and outputting it to 'titanic_predict.py':\n",
    "! brainome -v -v -f NN data/titanic_train.csv -o titanic_predict.py -target Survived --yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Validate and Make Predictions\n",
    "\n",
    "We've built our first predictor! Now it's time to put it to use. In the case of Titanic, we are given test data from Kaggle, where it's different from the training data and doesn't include 'Survival'. We can use the model we built to make predictions for the test data and submit it to Kaggle for its competition. In the following code, I'll save the model's prediction in 'titanic_prediction.csv'. You will see that the predictor appended the model's prediction of survival as the last column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked,Prediction\n",
      "892,3,\"Kelly, Mr. James\",male,34.5,0,0,330911,7.8292,,Q,died\n",
      "893,3,\"Wilkes, Mrs. James (Ellen Needs)\",female,47,1,0,363272,7,,S,died\n",
      "894,2,\"Myles, Mr. Thomas Francis\",male,62,0,0,240276,9.6875,,Q,died\n",
      "895,3,\"Wirz, Mr. Albert\",male,27,0,0,315154,8.6625,,S,died\n",
      "896,3,\"Hirvonen, Mrs. Alexander (Helga E Lindqvist)\",female,22,1,1,3101298,12.2875,,S,died\n",
      "897,3,\"Svensson, Mr. Johan Cervin\",male,14,0,0,7538,9.225,,S,died\n",
      "898,3,\"Connolly, Miss. Kate\",female,30,0,0,330972,7.6292,,Q,died\n",
      "899,2,\"Caldwell, Mr. Albert Francis\",male,26,1,1,248738,29,,S,died\n",
      "900,3,\"Abrahim, Mrs. Joseph (Sophie Halaut Easu)\",female,18,0,0,2657,7.2292,,C,died\n"
     ]
    }
   ],
   "source": [
    "# Using predictor on test data and saving it to 'titanic_prediction.csv':\n",
    "! python3 titanic_predict.py data/titanic_test.csv > titanic_prediction.csv\n",
    "! head titanic_prediction.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have validation data, or data that has the target column but wasn't used for training, you can use it to validate the accuracy of your predictor, as we will do. For this particular instance, I found an annotated version of the Titanic test data, 'titanic_validation.csv', and used it to validate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Type:                    Neural Network\n",
      "System Type:                        2-way classifier\n",
      "\n",
      "Accuracy:\n",
      "    Best-guess accuracy:            61.25%\n",
      "    Model accuracy:                 61.25% (49/80 correct)\n",
      "    Improvement over best guess:    0.00% (of possible 38.75%)\n",
      "\n",
      "Model capacity (MEC):               27 bits\n",
      "Generalization ratio:               1.74 bits/bit\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "      Actual |   Predicted    \n",
      "    ----------------------------\n",
      "        died |      49        0\n",
      "    survived |      31        0\n",
      "\n",
      "Accuracy by Class:\n",
      "\n",
      "      target | TP FP TN FN     TPR     TNR     PPV     NPV      F1      TS\n",
      "    -------- | -- -- -- -- ------- ------- ------- ------- ------- -------\n",
      "        died | 49 31  0  0 100.00%   0.00%  61.25%   0.00%  75.97%  61.25%\n",
      "    survived |  0  0 49 31   0.00% 100.00%   0.00%  61.25%   0.00%   0.00%\n"
     ]
    }
   ],
   "source": [
    "# To validate:\n",
    "! python3 titanic_predict.py -validate data/titanic_validate.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From validating the predictor, we can see that it has 74.64% accuracy, 12.44% better than best-guess accuracy (which classifies all data points as the majority class). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Improving Our Model\n",
    "\n",
    "Our model did pretty well, but let's see if we can improve it. A column that contains a unique value in each row (for example a database key) will never contribute to generalization, so we shouldn't include database keys or other unique ID columns. We can remove these columns by using '-ignorecolumns'. We'll try ignoring columns: PassengerId, Name, Ticket, Cabin, Embarked, because they're all unique ID columns. We could also use '-rank' to rank columns by significance and only process contributing attributes.\n",
    "\n",
    "### Ignorecolumns vs Rank:\n",
    "There may be situations where domain knowledge suggests a better choice of features than -rank. If we know the data generative process, we can do better with -ignorecolumns than with -rank. Rank is also optimizing for quick clustering/decision tree. For neural networks, we may still wish to reduce input features, which can be done with pca, but at the cost of interpretability. Some applications may require the original features are used in which case pca isn't viable. Ignorecolumns can reduce features while maintaining interpretability and work better for neural networks than -rank may, but the burden of choosing the right columns to keep is now on us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using -ignorecolumns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Could not detect a GPU. Neural Network generation will be slow.\n",
      "\n",
      "\u001b[01;1mBrainome Table Compiler v1.005-7-prod\u001b[0m\n",
      "Copyright (c) 2019-2021 Brainome, Inc. All Rights Reserved.\n",
      "Licensed to:                 Alexander Makhratchev  (Evaluation)\n",
      "Expiration Date:             2021-08-31   22 days left\n",
      "Maximum File Size:           30 GB\n",
      "Maximum Instances:           unlimited\n",
      "Maximum Attributes:          unlimited\n",
      "Maximum Classes:             unlimited\n",
      "Connected to:                daimensions.brainome.ai  (local execution)\n",
      "\n",
      "\u001b[01;1mCommand:\u001b[0m\n",
      "    btc -v -v -f NN data/titanic_train.csv -o titanic_predict_igcol.py -target Survived -ignorecolumns PassengerId,Name,Ticket_Number,Cabin_Number,Port_of_Embarkation -e 10 --yes\n",
      "\n",
      "Start Time:                 08/09/2021, 11:10 PDT\n",
      "\n",
      "Cleaning...done. < 1s\n",
      "Splitting into training and validation...done. 1s\n",
      "Pre-training measurements...done. 11s\n",
      "\n",
      "\n",
      "\u001b[01;1mPre-training Measurements\u001b[0m\n",
      "Data:\n",
      "    Input:                      data/titanic_train.csv\n",
      "    Target Column:              Survived\n",
      "    Number of instances:        800\n",
      "    Number of attributes:         6 out of 11\n",
      "    Number of classes:            2\n",
      "\n",
      "Class Balance:                \n",
      "                            died: 61.50%\n",
      "                        survived: 38.50%\n",
      "\n",
      "Learnability:\n",
      "    Best guess accuracy:          61.50%\n",
      "    Data Sufficiency:             Maybe enough data to generalize. [yellow]\n",
      "\n",
      "Capacity Progression:             at [ 5%, 10%, 20%, 40%, 80%, 100% ]\n",
      "    Ideal Machine Learner:              4,   6,   7,   7,   8,   8\n",
      "\n",
      "Estimated Memory Equivalent Capacity:\n",
      "    Decision Tree:               210 bits\n",
      "    Neural Networks:              65 bits\n",
      "    Random Forest:                86 bits\n",
      "\n",
      "\n",
      "Percent of data that would be memorized:\n",
      "    Decision Tree:                57.59%\n",
      "    Neural Networks:              89.04%\n",
      "    Random Forest:                53.42%\n",
      "\n",
      "\n",
      "Expected Generalization:\n",
      "    Decision Tree:                 3.53 bits/bit\n",
      "    Neural Network:               11.83 bits/bit\n",
      "    Random Forest:                 9.30 bits/bit\n",
      "\n",
      "Expected Accuracy:              Training            Validation\n",
      "    Decision Tree:                96.25%                70.00%\n",
      "    Neural Network:                 ----                  ----\n",
      "    Random Forest:                99.00%                77.50%\n",
      "\n",
      "Recommendations:\n",
      "    We recommend using Random Forest -f RF.\n",
      "    If predictor accuracy is insufficient, try using the option -rank to automatically select the important attributes.\n",
      "    Model type NN given by user. \n",
      "\n",
      "\n",
      "Architecting model...done. 5s\n",
      "Priming model...done. 1m\n",
      "Training...done. 5m 1s\n",
      "Model created:\n",
      "Sequential(\n",
      "  (0): Linear(in_features=6, out_features=2, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "Compiling predictor...done. < 1s\n",
      "Validating predictor...done. 1s\n",
      "\n",
      "\u001b[01;1mPredictor:\u001b[0m                        titanic_predict_igcol.py\n",
      "    Classifier Type:              Neural Network\n",
      "    System Type:                  Binary classifier\n",
      "    Training / Validation Split:  50% : 50%\n",
      "    Accuracy:\n",
      "      Best-guess accuracy:        61.50%\n",
      "      Training accuracy:          81.75% (327/400 correct)\n",
      "      Validation Accuracy:        84.00% (336/400 correct)\n",
      "      Combined Model Accuracy:    82.87% (663/800 correct)\n",
      "\n",
      "    Model Capacity (MEC):         17    bits\n",
      "\n",
      "    Generalization Ratio:         18.49 bits/bit\n",
      "    Percent of Data Memorized:    10.98%\n",
      "    Resilience to Noise:          -1.28 dB\n",
      "    System Meter Runtime Duration:    1s\n",
      "\n",
      "    Training Confusion Matrix:\n",
      "              Actual | Predicted\n",
      "              ------ | ---------\n",
      "                died |  220   26 \n",
      "            survived |   47  107 \n",
      "\n",
      "    Validation Confusion Matrix:\n",
      "              Actual | Predicted\n",
      "              ------ | ---------\n",
      "                died |  225   21 \n",
      "            survived |   43  111 \n",
      "\n",
      "    Combined Confusion Matrix:\n",
      "              Actual | Predicted\n",
      "              ------ | ---------\n",
      "                died |  445   47 \n",
      "            survived |   90  218 \n",
      "\n",
      "    Training Accuracy by Class:\n",
      "            Survived |   TP   FP   TN   FN     TPR      TNR      PPV      NPV       F1       TS \n",
      "            -------- | ---- ---- ---- ---- -------- -------- -------- -------- -------- --------\n",
      "                died |  220   47  107   26   89.43%   69.48%   82.40%   80.45%   85.77%   75.09%\n",
      "            survived |  107   26  220   47   69.48%   89.43%   80.45%   82.40%   74.56%   59.44%\n",
      "\n",
      "    Validation Accuracy by Class:\n",
      "            Survived |   TP   FP   TN   FN     TPR      TNR      PPV      NPV       F1       TS \n",
      "            -------- | ---- ---- ---- ---- -------- -------- -------- -------- -------- --------\n",
      "                died |  225   43  111   21   91.46%   72.08%   83.96%   84.09%   87.55%   77.85%\n",
      "            survived |  111   21  225   43   72.08%   91.46%   84.09%   83.96%   77.62%   63.43%\n",
      "\n",
      "    Combined Accuracy by Class:\n",
      "            Survived |   TP   FP   TN   FN     TPR      TNR      PPV      NPV       F1       TS \n",
      "            -------- | ---- ---- ---- ---- -------- -------- -------- -------- -------- --------\n",
      "                died |  445   90  218   47   90.45%   70.78%   83.18%   82.26%   86.66%   76.46%\n",
      "            survived |  218   47  445   90   70.78%   90.45%   82.26%   83.18%   76.09%   61.41%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "End Time:           08/09/2021, 11:16 PDT\n",
      "Runtime Duration:   6m 23s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using -ignorecolumns to make a better predictor:\n",
    "! brainome -v -v -f NN data/titanic_train.csv -o titanic_predict_igcol.py -target Survived -ignorecolumns PassengerId,Name,Ticket_Number,Cabin_Number,Port_of_Embarkation -e 10 --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked,Prediction\n",
      "892,3,\"Kelly, Mr. James\",male,34.5,0,0,330911,7.8292,,Q,died\n",
      "893,3,\"Wilkes, Mrs. James (Ellen Needs)\",female,47,1,0,363272,7,,S,died\n",
      "894,2,\"Myles, Mr. Thomas Francis\",male,62,0,0,240276,9.6875,,Q,died\n",
      "895,3,\"Wirz, Mr. Albert\",male,27,0,0,315154,8.6625,,S,died\n",
      "896,3,\"Hirvonen, Mrs. Alexander (Helga E Lindqvist)\",female,22,1,1,3101298,12.2875,,S,died\n",
      "897,3,\"Svensson, Mr. Johan Cervin\",male,14,0,0,7538,9.225,,S,died\n",
      "898,3,\"Connolly, Miss. Kate\",female,30,0,0,330972,7.6292,,Q,survived\n",
      "899,2,\"Caldwell, Mr. Albert Francis\",male,26,1,1,248738,29,,S,died\n",
      "900,3,\"Abrahim, Mrs. Joseph (Sophie Halaut Easu)\",female,18,0,0,2657,7.2292,,C,survived\n"
     ]
    }
   ],
   "source": [
    "# Using the ignorecolumns predictor on test data and saving it to 'titanic_prediction_igcol.csv':\n",
    "! python3 titanic_predict_igcol.py data/titanic_test.csv > titanic_prediction_igcol.csv\n",
    "! head titanic_prediction_igcol.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we wanted, -ignorecolumns removed the PassengerId, Name, Ticket, Cabin, and Embarked attributes. Next, we can use -validate to check the accuracy of our new predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Type:                    Neural Network\n",
      "System Type:                        2-way classifier\n",
      "\n",
      "Accuracy:\n",
      "    Best-guess accuracy:            61.25%\n",
      "    Model accuracy:                 80.00% (64/80 correct)\n",
      "    Improvement over best guess:    18.75% (of possible 38.75%)\n",
      "\n",
      "Model capacity (MEC):               17 bits\n",
      "Generalization ratio:               3.62 bits/bit\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "      Actual |   Predicted    \n",
      "    ----------------------------\n",
      "        died |      43        6\n",
      "    survived |      10       21\n",
      "\n",
      "Accuracy by Class:\n",
      "\n",
      "      target | TP FP TN FN     TPR     TNR     PPV     NPV      F1      TS\n",
      "    -------- | -- -- -- -- ------- ------- ------- ------- ------- -------\n",
      "        died | 43 10 21  6  87.76%  67.74%  81.13%  77.78%  84.31%  72.88%\n",
      "    survived | 21  6 43 10  67.74%  87.76%  77.78%  81.13%  72.41%  56.76%\n"
     ]
    }
   ],
   "source": [
    "# Validating the -ignorecolumns predictor\n",
    "! python3 titanic_predict_igcol.py -validate data/titanic_validate.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using -ignorecolumns has improved our accuracy to 80.00% from 74.64% originally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using -rank:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Could not detect a GPU. Neural Network generation will be slow.\n",
      "\n",
      "\u001b[01;1mBrainome Table Compiler v1.005-7-prod\u001b[0m\n",
      "Copyright (c) 2019-2021 Brainome, Inc. All Rights Reserved.\n",
      "Licensed to:                 Alexander Makhratchev  (Evaluation)\n",
      "Expiration Date:             2021-08-31   26 days left\n",
      "Maximum File Size:           30 GB\n",
      "Maximum Instances:           unlimited\n",
      "Maximum Attributes:          unlimited\n",
      "Maximum Classes:             unlimited\n",
      "Connected to:                daimensions.brainome.ai  (local execution)\n",
      "\n",
      "\u001b[01;1mCommand:\u001b[0m\n",
      "    btc -v -v -f NN data/titanic_train.csv -o titanic_predict_rank.py -target Survived -rank --yes -e 10\n",
      "\n",
      "Start Time:                 08/05/2021, 20:02 PDT\n",
      "\n",
      "Cleaning...done. < 1s\n",
      "Ranking attributes...done. < 1s\n",
      "\n",
      "\u001b[01;1mAttribute Ranking:\u001b[0m\n",
      "    Columns selected:           Sex, Sibling_Spouse, Parent_Children, Cabin_Class\n",
      "    Risk of coincidental column correlation:    0.0%\n",
      "    Ignoring columns:           PassengerId, Name, Age, Ticket_Number, Fare, Cabin_Number, Port_of_Embarkation\n",
      "    Test Accuracy Progression:\n",
      "                                          Sex :   78.75%\n",
      "                               Sibling_Spouse :   79.62% change   +0.88%\n",
      "                              Parent_Children :   80.25% change   +0.62%\n",
      "                                  Cabin_Class :   80.88% change   +0.63%\n",
      "         \n",
      "Splitting into training and validation...done. < 1s\n",
      "Pre-training measurements...done. 2s\n",
      "\n",
      "\n",
      "\u001b[01;1mPre-training Measurements\u001b[0m\n",
      "Data:\n",
      "    Input:                      data/titanic_train.csv\n",
      "    Target Column:              Survived\n",
      "    Number of instances:        800\n",
      "    Number of attributes:         4 out of 11\n",
      "    Number of classes:            2\n",
      "\n",
      "Class Balance:                \n",
      "                            died: 61.50%\n",
      "                        survived: 38.50%\n",
      "\n",
      "Learnability:\n",
      "    Best guess accuracy:          61.50%\n",
      "    Data Sufficiency:             Not enough data to generalize. [red]\n",
      "\n",
      "Capacity Progression:             at [ 5%, 10%, 20%, 40%, 80%, 100% ]\n",
      "    Ideal Machine Learner:              4,   5,   7,   7,   7,   8\n",
      "\n",
      "Estimated Memory Equivalent Capacity:\n",
      "    Decision Tree:                 1 bits\n",
      "    Neural Networks:              49 bits\n",
      "    Random Forest:                20 bits\n",
      "\n",
      "\n",
      "Percent of data that would be memorized:\n",
      "    Decision Tree:                 0.33%\n",
      "    Neural Networks:              89.09%\n",
      "    Random Forest:                11.43%\n",
      "\n",
      "\n",
      "Expected Generalization:\n",
      "    Decision Tree:               623.05 bits/bit\n",
      "    Neural Network:               15.70 bits/bit\n",
      "    Random Forest:                40.00 bits/bit\n",
      "\n",
      "Expected Accuracy:              Training            Validation\n",
      "    Decision Tree:                81.00%                80.88%\n",
      "    Neural Network:                 ----                  ----\n",
      "    Random Forest:                83.75%                79.00%\n",
      "\n",
      "Recommendations:\n",
      "    We recommend using Random Forest -f RF.\n",
      "    If predictor accuracy is insufficient, try using the option -rank to automatically select the important attributes.\n",
      "    Model type NN given by user. \n",
      "\n",
      "\n",
      "Architecting model...done. 5s\n",
      "Priming model...done. 20s\n",
      "Training...done. 3m 10s\n",
      "Model created:\n",
      "Sequential(\n",
      "  (0): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "Compiling predictor...done. < 1s\n",
      "Validating predictor...done. 1s\n",
      "\n",
      "\u001b[01;1mPredictor:\u001b[0m                        titanic_predict_rank.py\n",
      "    Classifier Type:              Neural Network\n",
      "    System Type:                  Binary classifier\n",
      "    Training / Validation Split:  50% : 50%\n",
      "    Accuracy:\n",
      "      Best-guess accuracy:        61.50%\n",
      "      Training accuracy:          79.25% (317/400 correct)\n",
      "      Validation Accuracy:        82.00% (328/400 correct)\n",
      "      Combined Model Accuracy:    80.62% (645/800 correct)\n",
      "\n",
      "    Model Capacity (MEC):         25    bits\n",
      "\n",
      "    Generalization Ratio:         12.19 bits/bit\n",
      "    Percent of Data Memorized:    16.65%\n",
      "    Resilience to Noise:          -1.10 dB\n",
      "    System Meter Runtime Duration:    1s\n",
      "\n",
      "    Training Confusion Matrix:\n",
      "              Actual | Predicted\n",
      "              ------ | ---------\n",
      "                died |  229   17 \n",
      "            survived |   66   88 \n",
      "\n",
      "    Validation Confusion Matrix:\n",
      "              Actual | Predicted\n",
      "              ------ | ---------\n",
      "                died |  228   18 \n",
      "            survived |   54  100 \n",
      "\n",
      "    Combined Confusion Matrix:\n",
      "              Actual | Predicted\n",
      "              ------ | ---------\n",
      "                died |  457   35 \n",
      "            survived |  120  188 \n",
      "\n",
      "    Training Accuracy by Class:\n",
      "            Survived |   TP   FP   TN   FN     TPR      TNR      PPV      NPV       F1       TS \n",
      "            -------- | ---- ---- ---- ---- -------- -------- -------- -------- -------- --------\n",
      "                died |  229   66   88   17   93.09%   57.14%   77.63%   83.81%   84.66%   73.40%\n",
      "            survived |   88   17  229   66   57.14%   93.09%   83.81%   77.63%   67.95%   51.46%\n",
      "\n",
      "    Validation Accuracy by Class:\n",
      "            Survived |   TP   FP   TN   FN     TPR      TNR      PPV      NPV       F1       TS \n",
      "            -------- | ---- ---- ---- ---- -------- -------- -------- -------- -------- --------\n",
      "                died |  228   54  100   18   92.68%   64.94%   80.85%   84.75%   86.36%   76.00%\n",
      "            survived |  100   18  228   54   64.94%   92.68%   84.75%   80.85%   73.53%   58.14%\n",
      "\n",
      "    Combined Accuracy by Class:\n",
      "            Survived |   TP   FP   TN   FN     TPR      TNR      PPV      NPV       F1       TS \n",
      "            -------- | ---- ---- ---- ---- -------- -------- -------- -------- -------- --------\n",
      "                died |  457  120  188   35   92.89%   61.04%   79.20%   84.30%   85.50%   74.67%\n",
      "            survived |  188   35  457  120   61.04%   92.89%   84.30%   79.20%   70.81%   54.81%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "End Time:           08/05/2021, 20:05 PDT\n",
      "Runtime Duration:   3m 41s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using -rank to make a better predictor:\n",
    "! brainome -v -v -f NN data/titanic_train.csv -o titanic_predict_rank.py -target Survived -rank --yes -e 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked,Prediction\n",
      "892,3,\"Kelly, Mr. James\",male,34.5,0,0,330911,7.8292,,Q,died\n",
      "893,3,\"Wilkes, Mrs. James (Ellen Needs)\",female,47,1,0,363272,7,,S,died\n",
      "894,2,\"Myles, Mr. Thomas Francis\",male,62,0,0,240276,9.6875,,Q,died\n",
      "895,3,\"Wirz, Mr. Albert\",male,27,0,0,315154,8.6625,,S,died\n",
      "896,3,\"Hirvonen, Mrs. Alexander (Helga E Lindqvist)\",female,22,1,1,3101298,12.2875,,S,died\n",
      "897,3,\"Svensson, Mr. Johan Cervin\",male,14,0,0,7538,9.225,,S,died\n",
      "898,3,\"Connolly, Miss. Kate\",female,30,0,0,330972,7.6292,,Q,survived\n",
      "899,2,\"Caldwell, Mr. Albert Francis\",male,26,1,1,248738,29,,S,died\n",
      "900,3,\"Abrahim, Mrs. Joseph (Sophie Halaut Easu)\",female,18,0,0,2657,7.2292,,C,survived\n"
     ]
    }
   ],
   "source": [
    "# Using the rank predictor on test data and saving it to 'titanic_prediction_rank.csv':\n",
    "! python3 titanic_predict_rank.py data/titanic_test.csv > titanic_prediction_rank.csv\n",
    "! head titanic_prediction_rank.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that -rank decided to only look at the columns 'Sex','Parch' (Parent/child), and 'Fare'. This makes a lot of sense that the determining factors for survival on the Titanic were sex, how many parents or children they had on board, and how much their fare was. Seeing what attributes -rank chooses gives us powerful insight into understanding our data and its correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Type:                    Neural Network\n",
      "System Type:                        2-way classifier\n",
      "\n",
      "Accuracy:\n",
      "    Best-guess accuracy:            61.25%\n",
      "    Model accuracy:                 80.00% (64/80 correct)\n",
      "    Improvement over best guess:    18.75% (of possible 38.75%)\n",
      "\n",
      "Model capacity (MEC):               25 bits\n",
      "Generalization ratio:               2.47 bits/bit\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "      Actual |   Predicted    \n",
      "    ----------------------------\n",
      "        died |      46        3\n",
      "    survived |      13       18\n",
      "\n",
      "Accuracy by Class:\n",
      "\n",
      "      target | TP FP TN FN     TPR     TNR     PPV     NPV      F1      TS\n",
      "    -------- | -- -- -- -- ------- ------- ------- ------- ------- -------\n",
      "        died | 46 13 18  3  93.88%  58.06%  77.97%  85.71%  85.19%  74.19%\n",
      "    survived | 18  3 46 13  58.06%  93.88%  85.71%  77.97%  69.23%  52.94%\n"
     ]
    }
   ],
   "source": [
    "# Validating the -rank predictor\n",
    "! python3 titanic_predict_rank.py -validate data/titanic_validate.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With -rank, our accuracy is 80.00%, again, an improvement over our original 74.64%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Using a Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will be using a different model that the Brainome Table Compiler has to offer: a decision tree. We will also be using the -rank command in order to select the most correlated columns with the survival column. This will prevent us from overfitting our model with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Could not detect a GPU. Neural Network generation will be slow.\n",
      "\n",
      "\u001b[01;1mBrainome Table Compiler v1.005-7-prod\u001b[0m\n",
      "Copyright (c) 2019-2021 Brainome, Inc. All Rights Reserved.\n",
      "Licensed to:                 Alexander Makhratchev  (Evaluation)\n",
      "Expiration Date:             2021-08-31   25 days left\n",
      "Maximum File Size:           30 GB\n",
      "Maximum Instances:           unlimited\n",
      "Maximum Attributes:          unlimited\n",
      "Maximum Classes:             unlimited\n",
      "Connected to:                daimensions.brainome.ai  (local execution)\n",
      "\n",
      "\u001b[01;1mCommand:\u001b[0m\n",
      "    btc data/titanic_train.csv -rank -f DT -o titanic_predict_DT.py\n",
      "\n",
      "Start Time:                 08/06/2021, 19:07 PDT\n",
      "\n",
      "Cleaning...done. \n",
      "Ranking attributes...done. \n",
      "\n",
      "\u001b[01;1mAttribute Ranking:\u001b[0m\n",
      "    Columns selected:           Sex, Sibling_Spouse, Parent_Children, Cabin_Class\n",
      "    Risk of coincidental column correlation:    0.0%\n",
      "    \n",
      "    Test Accuracy Progression:\n",
      "                                          Sex :   78.75%\n",
      "                               Sibling_Spouse :   79.62% change   +0.88%\n",
      "                              Parent_Children :   80.25% change   +0.62%\n",
      "                                  Cabin_Class :   80.88% change   +0.63%\n",
      "         \n",
      "Splitting into training and validation...done. \n",
      "Pre-training measurements...done. \n",
      "\n",
      "\n",
      "\u001b[01;1mPre-training Measurements\u001b[0m\n",
      "Data:\n",
      "    Input:                      data/titanic_train.csv\n",
      "    Target Column:              Survived\n",
      "    Number of instances:        800\n",
      "    Number of attributes:         4 out of 11\n",
      "    Number of classes:            2\n",
      "\n",
      "Class Balance:                \n",
      "                            died: 61.50%\n",
      "                        survived: 38.50%\n",
      "\n",
      "Learnability:\n",
      "    Best guess accuracy:          61.50%\n",
      "    Data Sufficiency:             Not enough data to generalize. [red]\n",
      "\n",
      "Capacity Progression:             at [ 5%, 10%, 20%, 40%, 80%, 100% ]\n",
      "    Ideal Machine Learner:              4,   5,   7,   7,   7,   8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Expected Generalization:\n",
      "    Decision Tree:               623.05 bits/bit\n",
      "    Neural Network:               15.70 bits/bit\n",
      "    Random Forest:                40.00 bits/bit\n",
      "\n",
      "Expected Accuracy:              Training            Validation\n",
      "    Decision Tree:                81.00%                80.88%\n",
      "    Neural Network:                 ----                  ----\n",
      "    Random Forest:                83.75%                79.00%\n",
      "\n",
      "Recommendations:\n",
      "    We recommend using Random Forest -f RF.\n",
      "    If predictor accuracy is insufficient, try using the option -rank to automatically select the important attributes.\n",
      "    If predictor accuracy is insufficient, try using the effort option -e with a value of 5 or more to increase training time.\n",
      "    Model type DT given by user. \n",
      "\n",
      "Time to Build Estimates:\n",
      "    Decision Tree:                a few seconds\n",
      "\n",
      "\n",
      "Building classifier...done. \n",
      "Compiling predictor...done. \n",
      "Validating predictor...done. \n",
      "\n",
      "\u001b[01;1mPredictor:\u001b[0m                        titanic_predict_DT.py\n",
      "    Classifier Type:              Decision Tree\n",
      "    System Type:                  Binary classifier\n",
      "    Training / Validation Split:  50% : 50%\n",
      "    Accuracy:\n",
      "      Best-guess accuracy:        61.50%\n",
      "      Training accuracy:          82.00% (328/400 correct)\n",
      "      Validation Accuracy:        80.00% (320/400 correct)\n",
      "      Combined Model Accuracy:    81.00% (648/800 correct)\n",
      "\n",
      "    Model Capacity (MEC):          1    bits\n",
      "\n",
      "    Generalization Ratio:        315.37 bits/bit\n",
      "    Percent of Data Memorized:     0.64%\n",
      "    Resilience to Noise:          -2.52 dB\n",
      "\n",
      "\n",
      "    Training Confusion Matrix:\n",
      "              Actual | Predicted\n",
      "              ------ | ---------\n",
      "                died |  222   24 \n",
      "            survived |   48  106 \n",
      "\n",
      "    Validation Confusion Matrix:\n",
      "              Actual | Predicted\n",
      "              ------ | ---------\n",
      "                died |  219   27 \n",
      "            survived |   53  101 \n",
      "\n",
      "    Training Accuracy by Class:\n",
      "            Survived |   TP   FP   TN   FN     TPR      TNR      PPV      NPV       F1       TS \n",
      "            -------- | ---- ---- ---- ---- -------- -------- -------- -------- -------- --------\n",
      "                died |  222   48  106   24   90.24%   68.83%   82.22%   81.54%   86.05%   75.51%\n",
      "            survived |  106   24  222   48   68.83%   90.24%   81.54%   82.22%   74.65%   59.55%\n",
      "\n",
      "    Validation Accuracy by Class:\n",
      "            Survived |   TP   FP   TN   FN     TPR      TNR      PPV      NPV       F1       TS \n",
      "            -------- | ---- ---- ---- ---- -------- -------- -------- -------- -------- --------\n",
      "                died |  219   53  101   27   89.02%   65.58%   80.51%   78.91%   84.56%   73.24%\n",
      "            survived |  101   27  219   53   65.58%   89.02%   78.91%   80.51%   71.63%   55.80%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "End Time:           08/06/2021, 19:08 PDT\n",
      "Runtime Duration:   13s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! brainome data/titanic_train.csv -rank -f DT -o titanic_predict_DT.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One think we notice is that the training and validation score are very similar to one another and this can be attributed to the fact that we did not overfit the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked,Prediction\n",
      "892,3,\"Kelly, Mr. James\",male,34.5,0,0,330911,7.8292,,Q,died\n",
      "893,3,\"Wilkes, Mrs. James (Ellen Needs)\",female,47,1,0,363272,7,,S,survived\n",
      "894,2,\"Myles, Mr. Thomas Francis\",male,62,0,0,240276,9.6875,,Q,died\n",
      "895,3,\"Wirz, Mr. Albert\",male,27,0,0,315154,8.6625,,S,died\n",
      "896,3,\"Hirvonen, Mrs. Alexander (Helga E Lindqvist)\",female,22,1,1,3101298,12.2875,,S,survived\n",
      "897,3,\"Svensson, Mr. Johan Cervin\",male,14,0,0,7538,9.225,,S,died\n",
      "898,3,\"Connolly, Miss. Kate\",female,30,0,0,330972,7.6292,,Q,survived\n",
      "899,2,\"Caldwell, Mr. Albert Francis\",male,26,1,1,248738,29,,S,died\n",
      "900,3,\"Abrahim, Mrs. Joseph (Sophie Halaut Easu)\",female,18,0,0,2657,7.2292,,C,survived\n"
     ]
    }
   ],
   "source": [
    "# Using the Decision Tree predictor on test data and saving it to 'titanic_prediction_DT.csv':\n",
    "! python3 titanic_predict_DT.py data/titanic_test.csv > titanic_prediction_DT.csv\n",
    "! head titanic_prediction_DT.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Type:                    Decision Tree\n",
      "System Type:                        2-way classifier\n",
      "\n",
      "Accuracy:\n",
      "    Best-guess accuracy:            61.25%\n",
      "    Model accuracy:                 81.25% (65/80 correct)\n",
      "    Improvement over best guess:    20.00% (of possible 38.75%)\n",
      "\n",
      "Model capacity (MEC):               1 bits\n",
      "Generalization ratio:               62.61 bits/bit\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "      Actual |   Predicted    \n",
      "    ----------------------------\n",
      "        died |      45        4\n",
      "    survived |      11       20\n",
      "\n",
      "Accuracy by Class:\n",
      "\n",
      "      target | TP FP TN FN     TPR     TNR     PPV     NPV      F1      TS\n",
      "    -------- | -- -- -- -- ------- ------- ------- ------- ------- -------\n",
      "        died | 45 11 20  4  91.84%  64.52%  80.36%  83.33%  85.71%  75.00%\n",
      "    survived | 20  4 45 11  64.52%  91.84%  83.33%  80.36%  72.73%  57.14%\n"
     ]
    }
   ],
   "source": [
    "# Validating the DT predictor\n",
    "! python3 titanic_predict_DT.py -validate data/titanic_validate.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our accuracy has no gone up to 81.25% on the validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Random Forest Model\n",
    "\n",
    "Now we are going to try the third and final model that the Brainome Table Compiler has to offer: random forest classifier. A majority of the time this model will have the best result on the validation set and is able to trained fairly quickly eventhough it is more intensive than a decision tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Could not detect a GPU. Neural Network generation will be slow.\n",
      "\n",
      "\u001b[01;1mBrainome Table Compiler v1.005-7-prod\u001b[0m\n",
      "Copyright (c) 2019-2021 Brainome, Inc. All Rights Reserved.\n",
      "Licensed to:                 Alexander Makhratchev  (Evaluation)\n",
      "Expiration Date:             2021-08-31   25 days left\n",
      "Maximum File Size:           30 GB\n",
      "Maximum Instances:           unlimited\n",
      "Maximum Attributes:          unlimited\n",
      "Maximum Classes:             unlimited\n",
      "Connected to:                daimensions.brainome.ai  (local execution)\n",
      "\n",
      "\u001b[01;1mCommand:\u001b[0m\n",
      "    btc data/titanic_train.csv -rank -f RF -o titanic_predict_RF.py\n",
      "\n",
      "Start Time:                 08/06/2021, 19:21 PDT\n",
      "\n",
      "Cleaning...done. \n",
      "Ranking attributes...done. \n",
      "\n",
      "\u001b[01;1mAttribute Ranking:\u001b[0m\n",
      "    Columns selected:           Sex, Sibling_Spouse, Parent_Children, Cabin_Class\n",
      "    Risk of coincidental column correlation:    0.0%\n",
      "    \n",
      "    Test Accuracy Progression:\n",
      "                                          Sex :   78.75%\n",
      "                               Sibling_Spouse :   79.62% change   +0.88%\n",
      "                              Parent_Children :   80.25% change   +0.62%\n",
      "                                  Cabin_Class :   80.88% change   +0.63%\n",
      "         \n",
      "Splitting into training and validation...done. \n",
      "Pre-training measurements...done. \n",
      "\n",
      "\n",
      "\u001b[01;1mPre-training Measurements\u001b[0m\n",
      "Data:\n",
      "    Input:                      data/titanic_train.csv\n",
      "    Target Column:              Survived\n",
      "    Number of instances:        800\n",
      "    Number of attributes:         4 out of 11\n",
      "    Number of classes:            2\n",
      "\n",
      "Class Balance:                \n",
      "                            died: 61.50%\n",
      "                        survived: 38.50%\n",
      "\n",
      "Learnability:\n",
      "    Best guess accuracy:          61.50%\n",
      "    Data Sufficiency:             Not enough data to generalize. [red]\n",
      "\n",
      "Capacity Progression:             at [ 5%, 10%, 20%, 40%, 80%, 100% ]\n",
      "    Ideal Machine Learner:              4,   5,   7,   7,   7,   8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Expected Generalization:\n",
      "    Decision Tree:               623.05 bits/bit\n",
      "    Neural Network:               15.70 bits/bit\n",
      "    Random Forest:                40.00 bits/bit\n",
      "\n",
      "Expected Accuracy:              Training            Validation\n",
      "    Decision Tree:                81.00%                80.88%\n",
      "    Neural Network:                 ----                  ----\n",
      "    Random Forest:                83.75%                79.00%\n",
      "\n",
      "Recommendations:\n",
      "    We recommend using Random Forest -f RF.\n",
      "    If predictor accuracy is insufficient, try using the option -rank to automatically select the important attributes.\n",
      "    If predictor accuracy is insufficient, try using the effort option -e with a value of 5 or more to increase training time.\n",
      "    Model type RF given by user. \n",
      "\n",
      "\n",
      "Building classifier...done. \n",
      "Compiling predictor...done. \n",
      "Validating predictor...done. \n",
      "\n",
      "\u001b[01;1mPredictor:\u001b[0m                        titanic_predict_RF.py\n",
      "    Classifier Type:              Random Forest\n",
      "    System Type:                  Binary classifier\n",
      "    Training / Validation Split:  50% : 50%\n",
      "    Accuracy:\n",
      "      Best-guess accuracy:        61.50%\n",
      "      Training accuracy:          82.00% (328/400 correct)\n",
      "      Validation Accuracy:        79.50% (318/400 correct)\n",
      "      Combined Model Accuracy:    80.75% (646/800 correct)\n",
      "\n",
      "    Model Capacity (MEC):         17    bits\n",
      "\n",
      "    Generalization Ratio:         18.55 bits/bit\n",
      "    Percent of Data Memorized:    10.95%\n",
      "    Resilience to Noise:          -1.29 dB\n",
      "\n",
      "\n",
      "    Training Confusion Matrix:\n",
      "              Actual | Predicted\n",
      "              ------ | ---------\n",
      "                died |  221   25 \n",
      "            survived |   47  107 \n",
      "\n",
      "    Validation Confusion Matrix:\n",
      "              Actual | Predicted\n",
      "              ------ | ---------\n",
      "                died |  217   29 \n",
      "            survived |   53  101 \n",
      "\n",
      "    Training Accuracy by Class:\n",
      "            Survived |   TP   FP   TN   FN     TPR      TNR      PPV      NPV       F1       TS \n",
      "            -------- | ---- ---- ---- ---- -------- -------- -------- -------- -------- --------\n",
      "                died |  221   47  107   25   89.84%   69.48%   82.46%   81.06%   85.99%   75.43%\n",
      "            survived |  107   25  221   47   69.48%   89.84%   81.06%   82.46%   74.83%   59.78%\n",
      "\n",
      "    Validation Accuracy by Class:\n",
      "            Survived |   TP   FP   TN   FN     TPR      TNR      PPV      NPV       F1       TS \n",
      "            -------- | ---- ---- ---- ---- -------- -------- -------- -------- -------- --------\n",
      "                died |  217   53  101   29   88.21%   65.58%   80.37%   77.69%   84.11%   72.58%\n",
      "            survived |  101   29  217   53   65.58%   88.21%   77.69%   80.37%   71.13%   55.19%\n",
      "\n",
      "\n",
      "    Attribute Ranking:\n",
      "                                      Feature | Relative Importance\n",
      "                                          Sex :   0.6698\n",
      "                                  Cabin_Class :   0.2146\n",
      "                              Parent_Children :   0.0622\n",
      "                               Sibling_Spouse :   0.0533\n",
      "         \n",
      "\n",
      "\n",
      "\n",
      "End Time:           08/06/2021, 19:21 PDT\n",
      "Runtime Duration:   14s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! brainome data/titanic_train.csv -rank -f RF -o titanic_predict_RF.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked,Prediction\n",
      "892,3,\"Kelly, Mr. James\",male,34.5,0,0,330911,7.8292,,Q,died\n",
      "893,3,\"Wilkes, Mrs. James (Ellen Needs)\",female,47,1,0,363272,7,,S,survived\n",
      "894,2,\"Myles, Mr. Thomas Francis\",male,62,0,0,240276,9.6875,,Q,died\n",
      "895,3,\"Wirz, Mr. Albert\",male,27,0,0,315154,8.6625,,S,died\n",
      "896,3,\"Hirvonen, Mrs. Alexander (Helga E Lindqvist)\",female,22,1,1,3101298,12.2875,,S,survived\n",
      "897,3,\"Svensson, Mr. Johan Cervin\",male,14,0,0,7538,9.225,,S,died\n",
      "898,3,\"Connolly, Miss. Kate\",female,30,0,0,330972,7.6292,,Q,survived\n",
      "899,2,\"Caldwell, Mr. Albert Francis\",male,26,1,1,248738,29,,S,died\n",
      "900,3,\"Abrahim, Mrs. Joseph (Sophie Halaut Easu)\",female,18,0,0,2657,7.2292,,C,survived\n"
     ]
    }
   ],
   "source": [
    "# Using the Random Forest predictor on test data and saving it to 'titanic_prediction_RF.csv':\n",
    "! python3 titanic_predict_RF.py data/titanic_test.csv > titanic_prediction_RF.csv\n",
    "! head titanic_prediction_RF.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Type:                    Random Forest\n",
      "System Type:                        2-way classifier\n",
      "\n",
      "Accuracy:\n",
      "    Best-guess accuracy:            61.25%\n",
      "    Model accuracy:                 80.00% (64/80 correct)\n",
      "    Improvement over best guess:    18.75% (of possible 38.75%)\n",
      "\n",
      "Model capacity (MEC):               17 bits\n",
      "Generalization ratio:               3.62 bits/bit\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "      Actual |   Predicted    \n",
      "    ----------------------------\n",
      "        died |      45        4\n",
      "    survived |      12       19\n",
      "\n",
      "Accuracy by Class:\n",
      "\n",
      "      target | TP FP TN FN     TPR     TNR     PPV     NPV      F1      TS\n",
      "    -------- | -- -- -- -- ------- ------- ------- ------- ------- -------\n",
      "        died | 45 12 19  4  91.84%  61.29%  78.95%  82.61%  84.91%  73.77%\n",
      "    survived | 19  4 45 12  61.29%  91.84%  82.61%  78.95%  70.37%  54.29%\n"
     ]
    }
   ],
   "source": [
    "# Validating the DT predictor\n",
    "! python3 titanic_predict_RF.py -validate data/titanic_validate.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our accuracy is 80.00% on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Next Steps\n",
    "\n",
    "Success! We've built our first predictor and used it to make predictions on the Titanic test data. From here, we can use our model on any new Titanic data or use other control options to try to improve our results even more.\n",
    "To check out some of the other control options, use '-h' to see the full list. You can also check out Brainome's How-to Guide and Glossary for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: brainome [-h] [-version] [-headerless] [-target TARGET]\n",
      "                [-ignorecolumns IGNORECOLUMNS] [-rank [ATTRIBUTERANK]]\n",
      "                [-measureonly] [-f FORCEMODEL] [-nosplit] [-split FORCESPLIT]\n",
      "                [-nsamples NSAMPLES] [-ignoreclasses IGNORELABELS]\n",
      "                [-usecolumns IMPORTANTCOLUMNS] [-o OUTPUT] [-v] [-q] [-y]\n",
      "                [-e EFFORT] [-biasmeter] [-novalidation] [-balance]\n",
      "                [-O OPTIMIZE] [-nofun] [-modelonly]\n",
      "                input [input ...]\n",
      "\n",
      "\u001b[01;30mBrainome Table Compiler (tm)  v1.005-7-prod\u001b[0m\n",
      "\n",
      "\u001b[01;1mRequired arguments\u001b[0m:\n",
      "  input                 Table as CSV files and/or URLs or Command above\n",
      "\n",
      "\u001b[01;1mOptional arguments\u001b[0m:\n",
      "  -h                    show this help message and exit\n",
      "  -version              show program's version number and exit\n",
      "\n",
      "\u001b[01;1mBasic options\u001b[0m:\n",
      "  -headerless           Headerless CSV input file.\n",
      "  -target TARGET        Specify target column by name or number. Default: last column of table.\n",
      "  -ignorecolumns IGNORECOLUMNS\n",
      "                        Comma-separated list of columns to ignore by name or number.\n",
      "  -rank [ATTRIBUTERANK]\n",
      "                        Select the optimal subset of columns for accuracy on held out data\n",
      "                        If optional parameter N is given, select the optimal N columns. Works best for DT.\n",
      "  -measureonly          Only output measurements, no predictor is built.\n",
      "  -f FORCEMODEL         Force model type: DT, NN, RF  Default: RF\n",
      "  -nosplit              Use all of the data for training. Default: dataset is split between training and validation.\n",
      "  -split FORCESPLIT     Pass it an integer between 50 and 90 telling forcing our system to use that percent of the data for training, and the rest for validation\n",
      "\n",
      "\u001b[01;1mIntermediate options\u001b[0m:\n",
      "  -nsamples NSAMPLES    Train only on a subset of N random samples of the dataset. Default: entire dataset.\n",
      "  -ignoreclasses IGNORELABELS\n",
      "                        Comma-separated list of classes to ignore.\n",
      "  -usecolumns IMPORTANTCOLUMNS\n",
      "                        Comma-separated list of columns by name or number used to build the predictor.\n",
      "  -o OUTPUT             Predictor filename. Default: a.py\n",
      "  -v                    Verbose output\n",
      "  -q                    Quiet operation.\n",
      "  -y                    Answers yes to all overwrite questions.\n",
      "\n",
      "\u001b[01;1mAdvanced options\u001b[0m:\n",
      "  -e EFFORT             Increase compute time to improve accuracy. 1=<EFFORT<100. Default: 1\n",
      "  -biasmeter            Measure model bias\n",
      "  -novalidation         Do not measure validation scores for created predictor.\n",
      "  -balance              Treat classes as if they were balanced (only active for NN).\n",
      "  -O OPTIMIZE           Maximize true positives towards a single class.\n",
      "  -nofun                Stop compilation if there are warnings.\n",
      "  -modelonly            Perform only the measurements needed to build the model.\n",
      "\n",
      "\u001b[01;1mExamples:\n",
      "\u001b[0mMeasure and build a random forest predictor for titanic\n",
      "\u001b[01;34m\tbrainome https://download.brainome.ai/data/public/titanic_train.csv \n",
      "\n",
      "\u001b[0mBuild a better predictor by ignoring columns:\n",
      "\u001b[01;34m\tbrainome titanic_train.csv -ignorecolumns \"PassengerId,Name\" -target Survived \n",
      "\n",
      "\u001b[0mAutomatically select the important columns by using ranking:\n",
      "\u001b[01;34m\tbrainome titanic_train.csv -rank -target Survived \n",
      "\n",
      "\u001b[0mBuild a neural network model with effort of 5:\n",
      "\u001b[01;34m\tbrainome titanic_train.csv -f NN -e 5 -target Survived\n",
      "\n",
      "\u001b[0mMeasure headerless dataset:\n",
      "\u001b[01;34m\tbrainome https://download.brainome.ai/data/public/bank.csv -headerless -measureonly\n",
      "\n",
      "\u001b[0mFull documentation can be found at https://www.brainome.ai/documentation\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! brainome -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "name": "python376jvsc74a57bd0a876d5d129613f84737ac732b9dceeab4d5b6e46c5cd6a0b580a7fe744c52632"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}